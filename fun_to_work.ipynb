{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run use_db_birulevo.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Удаление знаков препинания\n",
    "2. Удаление хештегов, ссылок\n",
    "3. Стемминг (mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymystem3 import Mystem\n",
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(txt, punctuation = True, hashtag = True, url = True, stem = True):\n",
    "    text = txt\n",
    "    if url:\n",
    "        text = re.sub('(http\\S+)|(www\\S+)|(pic\\S+)', ' ', text)\n",
    "    if hashtag:\n",
    "        text = re.sub('#\\w+', ' ', text)\n",
    "    if punctuation:\n",
    "        text = re.sub('[^a-zA-Zа-яА-Я1-9@_#]+', ' ', text)\n",
    "    if stem:\n",
    "        lemmas = mystem.lemmatize(text)\n",
    "        text = ''.join(lemmas)\n",
    "    return (text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлечение из базы данных в текстовый файл сообщений пользователей и меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mess_to_txt (user, out_file, punctuation = False, hashtag = False, \n",
    "                 url = False, stem = False, errors = False):\n",
    "    start = time.time()\n",
    "    query = 'select count(*) from author'\n",
    "    count = query_with_fetchone(user, query)\n",
    "    marks = []\n",
    "    for i in range(1, count[0][0] + 1):\n",
    "        query = 'select mark from author where id = ' + str(i)\n",
    "        marks.append(int(query_with_fetchone(user, query)[0][0]))\n",
    "    try:\n",
    "        with open(out_file, 'w') as f:\n",
    "             for i in range(1, count[0][0] + 1):\n",
    "                    query = 'select mess from messages where author = ' + str(i)\n",
    "                    list_mess = query_with_fetchone(user, query)\n",
    "                    for mess in list_mess:\n",
    "                        st = mess[0]\n",
    "                        #if errors:\n",
    "                            # bla-bla, use pyaspeller\n",
    "                        if (punctuation or hashtag or url or stem):\n",
    "                            st = preprocess_text(st, punctuation, hashtag, url, stem)\n",
    "                        else:\n",
    "                            st = re.sub('\\n', ' ', st)\n",
    "                        if (st == ''):\n",
    "                            continue\n",
    "                        f.write(st + ' ')\n",
    "                    f.write('\\n')\n",
    "    except IOError:\n",
    "        print(\"An IOError has occurred!\")\n",
    "    print (time.time() - start)\n",
    "    return marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создание модели векторов word2vec из текстового файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import multiprocessing\n",
    "import gensim\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_w2v (file_txt, save_model, size = 200, window = 5, min_count = 3):\n",
    "    start = time.time()\n",
    "    data = gensim.models.word2vec.LineSentence(file_txt)\n",
    "    model = Word2Vec(data, size = size, window = window, min_count = min_count, \n",
    "                     workers=multiprocessing.cpu_count())\n",
    "    end = time.time()\n",
    "    model.save(save_model)\n",
    "    return (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_w2v(name_model):\n",
    "    return Word2Vec.load(name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_vec (list_words, model, num_features):\n",
    "    feature_vec = np.zeros((num_features), dtype = \"float32\")\n",
    "    count_words = 0\n",
    "    set_words_model = set(model.wv.index2word)\n",
    "    for word in list_words:\n",
    "        if word in set_words_model:\n",
    "            count_words += 1\n",
    "            feature_vec = np.add(feature_vec, model.wv[word])\n",
    "    feature_vec = np.divide(feature_vec, count_words)\n",
    "    return (feature_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_words(text):\n",
    "    st = re.sub('[^a-zA-Zа-яА-Я1-9@_#]+', ' ', text)\n",
    "    list_words = st.split()\n",
    "    for word in list_words:\n",
    "        word = word.strip()\n",
    "    return (list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_vec (file_txt, model):\n",
    "    start = time.time()\n",
    "    num_features = model.wv.vector_size\n",
    "    text_vec = []\n",
    "    try:\n",
    "        with open(file_txt, 'r') as f:\n",
    "            st = f.readline()\n",
    "            while (st != \"\"):\n",
    "                list_words = text_to_words(st)\n",
    "                text_vec.append(create_feature_vec(list_words, model, num_features))\n",
    "                st = f.readline()\n",
    "    except IOError:\n",
    "        print(\"An IOError has occurred!\")\n",
    "    print(time.time() - start)\n",
    "    return np.array(text_vec, dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame(text_vec, marks):\n",
    "    df = pd.DataFrame(text_vec)\n",
    "    df['marks'] = marks\n",
    "    return (df.loc[(df.marks == -1) | (df.marks == 1)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_random_forest_kf(X, y, n_splitsKF, min_estimators, max_estimators):\n",
    "    \n",
    "    kf = KFold(n_splits = n_splitsKF)#, shuffle = True, random_state = 1)\n",
    "    score_f1 = np.zeros(max_estimators - min_estimators + 1)\n",
    "    for k in range(min_estimators, max_estimators + 1):\n",
    "        forest_class = RandomForestClassifier(n_estimators = k)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            forest_class.fit(X_train, y_train)\n",
    "            predict = forest_class.predict(X_test)\n",
    "            score_f1[k-1] += f1_score(y_test, predict)\n",
    "    score_f1 /= n_splitsKF\n",
    "    return score_f1.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_random_forest(df, marks,n_splitsKF, min_estimators, max_estimators):\n",
    "    start = time.time()\n",
    "    X = df[new_df.columns[:-1]]\n",
    "    y = df[marks]\n",
    "    k = class_random_forest_kf(X, y, n_splitsKF, min_estimators, max_estimators)\n",
    "    kf = KFold(n_splits = n_splitsKF)#, shuffle = True, random_state = 1)\n",
    "    score_f1 = 0\n",
    "    score_acc = 0\n",
    "    score_rec = 0\n",
    "    score_prec = 0\n",
    "    fpr =dict()\n",
    "    tpr = dict()\n",
    "    i = 0\n",
    "    forest_class = RandomForestClassifier(n_estimators = k)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        forest_class.fit(X_train, y_train)\n",
    "        predict = forest_class.predict(X_test)\n",
    "        score_f1 += f1_score(y_test, predict)\n",
    "        score_acc += accuracy_score(y_test, predict)\n",
    "        score_rec += recall_score(y_test, predict)\n",
    "        score_prec += precision_score(y_test, predict)\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test, predict)\n",
    "        i += 1\n",
    "        \n",
    "    score_f1 /= n_splitsKF\n",
    "    score_acc /= n_splitsKF\n",
    "    score_rec /= n_splitsKF\n",
    "    score_prec /= n_splitsKF\n",
    "    fpr.values\n",
    "    auc_ = auc(sum(fpr.values())/len(fpr), sum(tpr.values())/len(tpr))\n",
    "    print(\"time = \", time.time() - start)\n",
    "    print(\"f1 = \", score_f1)\n",
    "    print(\"acc = \", score_acc)\n",
    "    print(\"rec = \", score_rec)\n",
    "    print(\"prec = \", score_prec)\n",
    "    print(\"auc = \", auc_)\n",
    "    plt.plot(sum(fpr.values())/len(fpr), sum(tpr.values())/len(tpr),  color='darkorange', \n",
    "             label='ROC curve (area = %0.2f)' %auc_)\n",
    "    plt.plot([0, 1], [0, 1], color='navy',linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Random Forest Classifier (k = %0.0f)' %k)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
